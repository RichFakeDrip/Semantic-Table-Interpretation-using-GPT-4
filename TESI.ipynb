{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ef3907-1e8b-4a34-8781-4b990313d6c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6591b921-9d2a-480c-b104-6c0298d502f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor\n",
    "!pip install openai\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import openai\n",
    "import requests\n",
    "import random\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "from termcolor import colored\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1351c0a6-db29-4f3c-8601-36fa4e5b59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_base = \"https://openaicremaschi.openai.azure.com/\"\n",
    "openai.api_key = \"ac741486314742dc9aca273fc7aadf37\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077d931-c96a-429e-bf03-3a2d94e3fa40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f461b36-4f9c-4c9c-bccc-7085a93134ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## OpenAI Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445051cc-76e4-4d65-9f03-8ef3e76675e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(myPrompt):\n",
    "    my_engine=\"gpt3\"\n",
    "    response = openai.Completion.create(\n",
    "      engine = my_engine,\n",
    "      prompt = myPrompt,\n",
    "      temperature = 0.1,\n",
    "      max_tokens = 200,\n",
    "      frequency_penalty = 0.2,\n",
    "      presence_penalty = 0.2,\n",
    "      stop = None) \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7026b7e-2655-4fc2-b897-28103a322fee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LamAPI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c1663d-59e1-42b2-b824-8057e8b5391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "url = \"https://lamapi.inside.disco.unimib.it/\"\n",
    "\n",
    "# Use LAMAPI to retrieve some entities from wikidata that could be suitable for the cell entity\n",
    "def lamapi_retrieval(cell):\n",
    "    cell = cell.strip()\n",
    "    params = {\n",
    "        'token': \"insideslab-lamapi-2022\",\n",
    "        'name': cell,\n",
    "        'kg': \"wikidata\",\n",
    "        'limit': 3\n",
    "        }\n",
    "    return s.get(\"https://lamapi.inside.disco.unimib.it/lookup/entity-retrieval\", headers=headers, params=params).json()[cell.lower()]\n",
    "\n",
    "# Use LAMAPI to identify the column type\n",
    "def lamapi_cta(column):\n",
    "    params = {\n",
    "        'token': \"insideslab-lamapi-2022\",\n",
    "        }\n",
    "    return s.post(url + \"sti/column-analysis\", headers=headers, params=params, json={\"json\":[column] }).json()\n",
    "\n",
    "#Use LAMAPI to retrieve the entity label from the entity id in wikidata\n",
    "def lamapi_entity_name(id):\n",
    "    params = {\n",
    "        'token': \"insideslab-lamapi-2022\",\n",
    "        'kg': \"wikidata\",\n",
    "        'lang':'en'\n",
    "        }\n",
    "    return s.post(url + \"entity/labels\", headers=headers, params=params, json={\"json\":[id]}).json()[\"wikidata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059085a-8c8c-4557-93fd-046a8eb70806",
   "metadata": {},
   "source": [
    "## Prompt Creation Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f0e53-580b-4d94-91b6-360e40d49e8c",
   "metadata": {},
   "source": [
    "### Prompt with pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75afe8f-8dc4-4707-97b9-0ebdd36fd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cea_prompt(cea_table, cea_pool_list):\n",
    "    cea_pool = \", \".join(map(str, cea_pool_list))\n",
    "    return \"\"\"\n",
    "    For each row r in table T:\n",
    "        For each field c in row r:\n",
    "            # Assume that the field contains an entity mention\n",
    "            entity_mention = r[c]\n",
    "            # Initialize a variable to track the best match\n",
    "            best_match = null\n",
    "            max_score = 0\n",
    "            # Search for matches in the entity pool P\n",
    "            For each entity p in pool P:\n",
    "                # Assume the function calculate_similarity_score returns a value representing the likelihood that the entity p is semantically appropriate for the entity_mention\n",
    "                score = calculate_similarity_score(entity_mention, p)\n",
    "                # Update the best match if the score is higher than the current maximum\n",
    "                If score > max_score:\n",
    "                    max_score = score\n",
    "                    best_match = p\n",
    "            # Assign the best match to the mention in the entity in the table\n",
    "            r[c] = best_match\n",
    "    \n",
    "    #Example usage:\n",
    "    table = \"\"\"+cea_table+\"\"\"\n",
    "    pool = \"\"\"+cea_pool+\"\"\"\n",
    "    Result = \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cd1bc4-7887-4ce7-ac53-4855ad81174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a table and return a iterable dictionary of its columns \n",
    "def create_columns(table):\n",
    "    columns = {}\n",
    "    for row in table.split(\"\\n\"):\n",
    "        for index, cell in enumerate(row.split(\",\")):   \n",
    "            if index not in columns:\n",
    "                columns[index] = [cell]\n",
    "            else:\n",
    "                columns[index].append(cell)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ae716a-d8db-4369-acb4-ac114a3bddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly choice 2 entities among the groundtruth entities in order to append them to the pool \n",
    "def random_choice(list):  \n",
    "    while True:\n",
    "        if len(list) < 2:\n",
    "            response_0 = lamapi_entity_name(list[0])\n",
    "            if response_0 != {}:\n",
    "                lab_entity_0 = response_0[list[0]][\"labels\"][\"en\"]\n",
    "                return list[0] + \" \" + lab_entity_0\n",
    "            else:\n",
    "                return 0\n",
    "        else:   \n",
    "            index_1, index_2 = random.sample(range(len(list)), 2)\n",
    "            response1 = lamapi_entity_name(list[index_1])\n",
    "            response2 = lamapi_entity_name(list[index_2])\n",
    "            if response1 != {}:\n",
    "                if response2 != {}:\n",
    "                    break\n",
    "    if response1[list[index_1]][\"labels\"].get(\"en\") is not None:\n",
    "        lab_entity_1 = response1[list[index_1]][\"labels\"][\"en\"]\n",
    "    else:\n",
    "        lab_entity_1 = \"generic\"\n",
    "    if response2[list[index_2]][\"labels\"].get(\"en\") is not None:\n",
    "        lab_entity_2 = response2[list[index_2]][\"labels\"][\"en\"]\n",
    "    else:\n",
    "        lab_entity_2 = \"generic\"\n",
    "    return list[index_1]+\" \"+lab_entity_1,list[index_2]+\" \"+lab_entity_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c64220-0476-4d31-acd8-3088feb5b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pool of suitable entities for the table \n",
    "def create_pool(table, table_id):\n",
    "    columns = create_columns(table)\n",
    "    cells_list = []\n",
    "    pool = []\n",
    "    for key, value in columns.items():\n",
    "        if lamapi_cta(value)[\"0\"][\"tag\"] == \"NE\":\n",
    "            for cell in value:\n",
    "                cells_list.append(cell)\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                temp_entities = list(executor.map(lamapi_retrieval, cells_list))\n",
    "            for newlist in temp_entities:\n",
    "                for index in range(len(newlist)):\n",
    "                    id_ent = newlist[index][\"id\"]\n",
    "                    name_ent = newlist[index][\"name\"]\n",
    "                    pool.append(f\"{id_ent} {name_ent}\")\n",
    "                pool.extend(random_choice(list(gt_dict[table_id].values())))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b4e11-4ab1-4672-9d31-74a8bb7e3ec1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prompt without pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee345c2-9116-4565-8e90-d33f0366ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cea_prompt_no_pool(cea_table):\n",
    "    return \"\"\"\n",
    "    T = â€¦\n",
    "    For each row r in table T:\n",
    "        For each field c in row r:\n",
    "            # Assume that the field contains an entity mention\n",
    "            entity_mention = r[c]\n",
    "    \n",
    "            # Initialize a variable to track the best match\n",
    "            best_match = null\n",
    "            max_score = 0\n",
    "    \n",
    "            # assume the get_entities_from_wikidata return entities from Wikidata that can be suitable for the entity_mention\n",
    "            candidate_entities = get_entities_from_wikidata(entity_mention)\n",
    "    \n",
    "            # Search for matches among candidate entities\n",
    "            For each wikidata_entity in candidate_entities:\n",
    "                # Calculate a similarity score between the mention in the table and the entity in Wikidata\n",
    "                score = calculate_similarity_score(entity_mention, wikidata_entity)\n",
    "    \n",
    "                # Update the best match if the score is higher than the current maximum\n",
    "                If score > max_score:\n",
    "                    max_score = score\n",
    "                    best_match = wikidata_entity\n",
    "    \n",
    "            # Assign the best match to the mention in the entity in the table\n",
    "            r[c] = best_match\n",
    "    \n",
    "    #Example usage:\n",
    "    table = \"\"\"+cea_table+\"\"\"\n",
    "    Result = \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d385dec-3a50-4c6b-9d20-4db0b22852db",
   "metadata": {},
   "source": [
    "## Prompt Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f7d154a-448a-4858-a4f5-a603fe0e286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute each prompt from the prompt list\n",
    "def execute_prompt(prompt_dict):\n",
    "    generation_dict = {}\n",
    "    i = 0\n",
    "    for key, value in tqdm_notebook(prompt_dict.items()):\n",
    "        generation_dict[key] = {}\n",
    "        time.sleep(0.3)\n",
    "        try:\n",
    "            generation_dict[key] = get_completion(value)[\"choices\"][0][\"text\"]\n",
    "        except:\n",
    "            i += 1\n",
    "    print(str(i)+\" Prompt Execution Error\")\n",
    "    return generation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317606f-d591-493d-a90c-7ac62eee62ac",
   "metadata": {},
   "source": [
    "## Parsing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ae1277-5272-4963-a203-6d9555791d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row and column number with the entity associated\n",
    "def entity_extractor(table_annotation, table_id):\n",
    "    result = []\n",
    "    for row_num, row in enumerate(table_annotation, start=1):\n",
    "        column = row.split(',')\n",
    "        for column_num, entity in enumerate(column):\n",
    "            match = re.search(r'Q\\d+', entity)\n",
    "            if match:\n",
    "                wiki_entity = match.group()\n",
    "                result.append(f\"{table_id}, {row_num}, {column_num}, {wiki_entity}\")\n",
    "    if len(result) == 0:\n",
    "        result.append(f\"{table_id}, No Wikidata Entities Found\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1885b7b9-69e1-4b34-8a7f-c310a52cc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the gpt response to keep only the table annotations\n",
    "def parser(raw_table_annotation):\n",
    "    if raw_table_annotation != {}:\n",
    "        rows = raw_table_annotation.split(\"\\n\")\n",
    "        result = []\n",
    "        found_empty_row = False    \n",
    "        for row in rows:\n",
    "            row = row.strip()\n",
    "            row = row.replace(\"\\t\", \",\")\n",
    "            if row == \"\":\n",
    "                found_empty_row = True\n",
    "            elif row == \"<|im_end|>\":\n",
    "                found_empty_row = True\n",
    "            elif found_empty_row:\n",
    "                break\n",
    "            elif row.endswith(\"<|im_end|>\"):\n",
    "                result.append(row.replace(\"<|im_end|>\", \"\"))\n",
    "            else:\n",
    "                result.append(row)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64425e2a-aed9-48b0-9d6c-f9b57220f009",
   "metadata": {},
   "source": [
    "## CSV Writing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a2e0f4-9b99-41fd-bc9e-6b95bb6d8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the annotation into a csv file\n",
    "def save_to_csv(file_name, list):\n",
    "    with open(file_name, mode='a', newline='') as file_csv:\n",
    "        writer = csv.writer(file_csv, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for element in list:\n",
    "            writer.writerow([element])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057faef-ee41-467e-abb9-f6afce7bb8ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GT_Table Dictionary Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9e93872-a103-4d9f-b889-ac10630e3ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc7ec422fff45ffb5372a40579245ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create the groundtruth dictionary \n",
    "cea_gt_path= [\n",
    "    \"./datasets/HardTablesR1/DataSets/HardTablesR1/Valid/gt/cea_gt.csv\",\n",
    "    \"./datasets/HardTablesR2/DataSets/HardTablesR2/Valid/gt/cea_gt.csv\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/GT/CEA/CEA_Round1_gt.csv\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/GT/CEA/CEA_Round2_gt.csv\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/GT/CEA/CEA_Round3_gt.csv\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/GT/CEA/CEA_Round4_gt.csv\",\n",
    "    \"./datasets/WikidataTables2023R1/DataSets/Valid/gt/cea_gt.csv\"\n",
    "]\n",
    "\n",
    "gt_dict = {}\n",
    "\n",
    "for cea_gt in tqdm_notebook(cea_gt_path):\n",
    "    with open(cea_gt) as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            table_id = row[0]\n",
    "            row_id = row[1]\n",
    "            column_id = row[2]\n",
    "            entity = row[3]\n",
    "            if table_id not in gt_dict:\n",
    "                gt_dict[table_id] = {}\n",
    "                gt_dict[table_id][f\"{row_id}_{column_id}\"] = entity.replace(\"http://www.wikidata.org/entity/\", \"\")\n",
    "            else:\n",
    "                gt_dict[table_id][f\"{row_id}_{column_id}\"] = entity.replace(\"http://www.wikidata.org/entity/\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a60df-1af9-4f10-9dc4-aeefbabf12b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table Prompts Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0226ef-af1f-4d8c-ada7-bdf46f2633f8",
   "metadata": {},
   "source": [
    "## Prompt with pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11c30c80-b30e-4796-8817-1dd72d0c2f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c76c6578a564df7a0769e03b0ade245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76dbed400224eb68cc9bef51f20c656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/HardTablesR1/DataSets/HardTablesR1/Valid/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738908d6f9d94bc29592cdb454093d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/HardTablesR2/DataSets/HardTablesR2/Valid/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c1fe56a95542e8a9beca6deecb022e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/WikidataTables2023R1/DataSets/Valid/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83addf2f883447a58cb4ce802ebea649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'iterazione del percorso ./datasets/SemTab2020_Table_GT_Target/Round1/tables ha superato 40 minuti.\n",
      "./datasets/SemTab2020_Table_GT_Target/Round1/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219adc1a32aa4257b5638f8d44dd918b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'iterazione del percorso ./datasets/SemTab2020_Table_GT_Target/Round2/tables ha superato 40 minuti.\n",
      "./datasets/SemTab2020_Table_GT_Target/Round2/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364c8719e96e4fa4863af744f79c45b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'iterazione del percorso ./datasets/SemTab2020_Table_GT_Target/Round3/tables ha superato 40 minuti.\n",
      "./datasets/SemTab2020_Table_GT_Target/Round3/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd17b1a85de451ca59b335099db92e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'iterazione del percorso ./datasets/SemTab2020_Table_GT_Target/Round4/tables ha superato 40 minuti.\n",
      "./datasets/SemTab2020_Table_GT_Target/Round4/tables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create the prompt with pool for each table\n",
    "tables_path= [\n",
    "    \"./datasets/HardTablesR1/DataSets/HardTablesR1/Valid/tables\",\n",
    "    \"./datasets/HardTablesR2/DataSets/HardTablesR2/Valid/tables\",\n",
    "    \"./datasets/WikidataTables2023R1/DataSets/Valid/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round1/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round2/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round3/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round4/tables\"\n",
    "]\n",
    "\n",
    "prompt_dict = {}\n",
    "max_min = 40\n",
    "\n",
    "# for each path\n",
    "for table_path in tqdm_notebook(tables_path):\n",
    "    # for each table in path\n",
    "    start_time = time.time() \n",
    "    for table in tqdm_notebook(os.listdir(table_path)):\n",
    "        # open CSV table at table_path/table\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > (max_min * 60):  # Converti i minuti in secondi\n",
    "            print(f\"L'iterazione del percorso {table_path} ha superato {max_min} minuti.\")\n",
    "            break\n",
    "        else:\n",
    "            table_id = table.replace(\".csv\", \"\")\n",
    "            if table.endswith('.csv') and gt_dict.get(table_id):\n",
    "                prompt_dict[table_id]={}\n",
    "                with open(table_path + '/' + table) as csvfile:\n",
    "                    # create a csv.reader object to read the csv file\n",
    "                    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "                    # skip the first header row and point to the second one\n",
    "                    next(spamreader)\n",
    "                    table_format = \"\"\n",
    "                    # for each row in csv.reader object \n",
    "                    for row in spamreader:   \n",
    "                       # transforms the current row into a string by joining its elements with commas\n",
    "                       current_row = \",\".join(row)\n",
    "                       # create the table by joining each string row\n",
    "                       table_format += f\"{current_row}\\n\"\n",
    "                    table_pool = list(set(create_pool(table_format, table_id)))\n",
    "                    prompt_dict[table_id] = create_cea_prompt(table_format, table_pool)\n",
    "    print(table_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f53c9-24b4-4e90-bcbd-103cc5aab7a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prompt without pool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda7c31e-e51e-4c52-9773-03db52007182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5f677951744e2a82ef7501698851a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef158e3ef25b4962a8640ac1b486fd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/HardTablesR1/DataSets/HardTablesR1/Valid/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb05e7bef944549ae2c49d9787d6c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/HardTablesR2/DataSets/HardTablesR2/Valid/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db606723aea4edca53002c33109b5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/WikidataTables2023R1/DataSets/Valid/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2082caafe9441aaa26f2e4afcd1b0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/SemTab2020_Table_GT_Target/Round1/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3c21011fa24e95b14b750ff4052322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/SemTab2020_Table_GT_Target/Round2/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa4ae36557d475787abe953fc246859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/SemTab2020_Table_GT_Target/Round3/tables\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8e4fc76b664afe8aac4f6e15e71f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/SemTab2020_Table_GT_Target/Round4/tables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create the prompt without pool for each table\n",
    "tables_path= [\n",
    "    \"./datasets/HardTablesR1/DataSets/HardTablesR1/Valid/tables\",\n",
    "    \"./datasets/HardTablesR2/DataSets/HardTablesR2/Valid/tables\",\n",
    "    \"./datasets/WikidataTables2023R1/DataSets/Valid/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round1/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round2/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round3/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round4/tables\"\n",
    "]\n",
    "\n",
    "prompt_dict_no_pool = {}\n",
    "max_min = 40\n",
    "\n",
    "# for each path\n",
    "for table_path in tqdm_notebook(tables_path):\n",
    "    # for each table in path\n",
    "    start_time = time.time() \n",
    "    for table in tqdm_notebook(os.listdir(table_path)):\n",
    "        # open CSV table at table_path/table\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > (max_min * 60):  # Converti i minuti in secondi\n",
    "            print(f\"L'iterazione del percorso {table_path} ha superato {max_min} minuti.\")\n",
    "            break\n",
    "        else:\n",
    "            table_id = table.replace(\".csv\", \"\")\n",
    "            if table.endswith('.csv') and gt_dict.get(table_id):\n",
    "                prompt_dict_no_pool[table_id]={}\n",
    "                with open(table_path + '/' + table) as csvfile:\n",
    "                    # create a csv.reader object to read the csv file\n",
    "                    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "                    # skip the first header row and point to the second one\n",
    "                    next(spamreader)\n",
    "                    table_format = \"\"\n",
    "                    # for each row in csv.reader object \n",
    "                    for row in spamreader:   \n",
    "                       # transforms the current row into a string by joining its elements with commas\n",
    "                       current_row = \",\".join(row)\n",
    "                       # create the table by joining each string row\n",
    "                       table_format += f\"{current_row}\\n\"\n",
    "                    prompt_dict_no_pool[table_id] = create_cea_prompt_no_pool(table_format)\n",
    "    print(table_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b32b4-c37c-4cba-8f2e-d0a83f8fcc4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompt with Pool Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78f46ad0-d4a9-451e-a764-c62d3719d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df3368487e94dc88b4437600e66264c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Prompt Execution Error\n"
     ]
    }
   ],
   "source": [
    "#Annotate each table using GPT\n",
    "raw_annotations = execute_prompt(prompt_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4c202-0a2c-4b94-bf79-a47fca160d6e",
   "metadata": {},
   "source": [
    "## Parsing and Writing Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27ca5d58-6c31-4e2c-beff-d67192657594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6d04096c8c4b838910bf78566302ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in tqdm_notebook(raw_annotations.items()):\n",
    "    if value != {}:\n",
    "        parsed_result = parser(value)\n",
    "        annotated_entities = entity_extractor(parsed_result, key)\n",
    "        save_to_csv(\"output.csv\", annotated_entities)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf1028-c2c6-4d03-b953-677e8c696aae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompt without Pool Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac9276-2af7-4da6-a866-67b040c36a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotate each table using GPT\n",
    "raw_annotations_no_pool = execute_prompt(prompt_dict_no_pool) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468b870-779c-426a-8fff-be80b412841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tqdm_notebook(raw_annotations_no_pool.items()):\n",
    "    parsed_result = parser(value)\n",
    "    annotated_entities = entity_extractor(parsed_result, key)\n",
    "    save_to_csv(\"output_no_pool.csv\", annotated_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e2d46a-77ce-48f4-9f75-f91d1de73ba8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompt with Pool Output Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f9f56-4733-45ea-a127-80a7c7bd7a30",
   "metadata": {},
   "source": [
    "## Stats Analysys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90c27788-4bee-401f-910d-6dc7953350ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEA groundtruth path\n",
    "ann_out= \"./output.csv\"\n",
    "\n",
    "ann_dict = {}\n",
    "\n",
    "with open(ann_out) as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    next(spamreader)\n",
    "    for row in spamreader:\n",
    "        for element in row:\n",
    "            my_list = element.split(\",\")\n",
    "            table_id = my_list[0]\n",
    "            if(my_list[1] != \" No Wikidata Entities Found\"):\n",
    "                row_id = my_list[1].strip()\n",
    "                column_id = my_list[2].strip()\n",
    "                entity = my_list[3].strip()\n",
    "                if table_id not in ann_dict:\n",
    "                    ann_dict[table_id] = {}\n",
    "                    ann_dict[table_id][f\"{row_id}_{column_id}\"] = entity\n",
    "                else:\n",
    "                    ann_dict[table_id][f\"{row_id}_{column_id}\"] = entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a72cb2fd-d9cb-46d1-9059-61249a75db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mOutput Analysis Prompt with Pool\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mNumber of tables: \u001b[0m2560\n",
      "\u001b[34mTabled correctly annotated: \u001b[0m105 (4.1%)\n",
      "\n",
      "\u001b[1m\u001b[31mNumber of annotable cells: \u001b[0m45568\n",
      "\u001b[34mCells correctly annotated: \u001b[0m6232 (13.68%)\n",
      "\u001b[34mCells misannotated: \u001b[0m11231 (24.65%)\n",
      "\u001b[34mMissing cells' annotation: \u001b[0m28105 (61.68%)\n"
     ]
    }
   ],
   "source": [
    "right_cell = 0\n",
    "wrong_cell = 0\n",
    "missing_cell = 0\n",
    "missing_table = 0\n",
    "entire_table = 0 \n",
    "n_cell = 0\n",
    "\n",
    "for key, value in gt_dict.items():\n",
    "    if key in ann_dict:\n",
    "        n_cell += len(gt_dict[key])\n",
    "        if gt_dict[key] == ann_dict[key]:  \n",
    "            entire_table += 1\n",
    "            right_cell += len(ann_dict[key])\n",
    "        else:\n",
    "            for gt_key, gt_value in gt_dict[key].items():\n",
    "                check = 0\n",
    "                try:\n",
    "                    num_cel_tab = len(gt_dict[key])\n",
    "                    if ann_dict[key][gt_key] == gt_value:\n",
    "                        right_cell += 1\n",
    "                        check += 1\n",
    "                    else:\n",
    "                        wrong_cell += 1                        \n",
    "                except:\n",
    "                    missing_cell += 1\n",
    "                if len(gt_dict[key]) == len(ann_dict[key]):\n",
    "                    if check == num_cel_tab:\n",
    "                        entire_table += 1\n",
    "\n",
    "\n",
    "print(colored(\"Output Analysis Prompt with Pool\",'red', attrs=['bold']))\n",
    "print(\"\")\n",
    "print(colored(\"Number of tables: \", 'red', attrs=['bold'])+ str(len(ann_dict)))  \n",
    "print(colored(\"Tabled correctly annotated: \", 'blue')+str(entire_table) + \" (\"+str(round(entire_table/len(ann_dict)*100, 2))+\"%)\")\n",
    "print(\"\")\n",
    "print(colored(\"Number of annotable cells: \", 'red', attrs=['bold'])+ str(n_cell))\n",
    "print(colored(\"Cells correctly annotated: \", 'blue')+str(right_cell)+\" (\"+str(round(right_cell/n_cell*100, 2))+\"%)\")\n",
    "print(colored(\"Cells misannotated: \", 'blue')+str(wrong_cell)+\" (\"+str(round(wrong_cell/n_cell*100, 2))+\"%)\")       \n",
    "print(colored(\"Missing cells' annotation: \", 'blue')+str(missing_cell)+\" (\"+str(round(missing_cell/n_cell*100, 2))+\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aab91c-d9d5-449b-85c6-4e56513b40ec",
   "metadata": {},
   "source": [
    "## Table Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90334822-fa5a-4c38-ac9b-0eb55733ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m\n",
      "GROUNDTRUTH ANNOTATIONS: QI8FPOEX\u001b[0m\n",
      "['1_0:Q98406669']\n",
      "['1_0:Q98406669', '2_0:Q96800889']\n",
      "['1_0:Q98406669', '2_0:Q96800889', '3_0:Q96106552']\n",
      "['4_0:Q96097699']\n",
      "['4_0:Q96097699', '5_0:Q95795329']\n",
      "['4_0:Q96097699', '5_0:Q95795329', '6_0:Q93095903']\n",
      "['7_0:Q93091566']\n",
      "\u001b[1m\u001b[31m\n",
      "GPT ANNOTATIONS: \u001b[0m\n",
      "['7_0:Q93091566', '1_1:Q116509058', '2_1:Q96800889']\n",
      "['3_1:Q96106552', '4_1:Q114353779', '5_1:Q95795329']\n",
      "['6_2:Q93095903', '7_2:Q1440300']\n",
      "\u001b[34m\n",
      "Correct cells annotation: \u001b[0m0\n",
      "\u001b[34mIncorrect cells annotation: \u001b[0m0\n",
      "\u001b[34mMissing cells annotation: \u001b[0m7\n"
     ]
    }
   ],
   "source": [
    "key = \"QI8FPOEX\"\n",
    "tab_right_cell = 0\n",
    "tab_wrong_cell = 0\n",
    "tab_missing_cell = 0\n",
    "print(colored(\"\\nGROUNDTRUTH ANNOTATIONS: \" + key , 'red', attrs=['bold']))\n",
    "if key in gt_dict:\n",
    "    value = gt_dict[key]\n",
    "    i = 0\n",
    "    temp_list = []\n",
    "    for col_row, value in gt_dict[key].items():\n",
    "        temp_list.append(col_row + \":\" + value)\n",
    "        if(len(temp_list) == 3):\n",
    "            print(temp_list)\n",
    "            temp_list = []\n",
    "        if temp_list:\n",
    "            print(temp_list)\n",
    "else:\n",
    "    print(colored(\"Do no exist gt table\", 'red'))\n",
    "print(colored(\"\\nGPT ANNOTATIONS: \", 'red', attrs=['bold']))\n",
    "if key in ann_dict:\n",
    "    for col_row, value in ann_dict[key].items():\n",
    "        temp_list.append(col_row + \":\" + value)\n",
    "        if(len(temp_list) == 3):\n",
    "            print(temp_list)\n",
    "            temp_list = []\n",
    "        try:\n",
    "            if gt_dict[key][col_row] == value:\n",
    "                tab_right_cell += 1\n",
    "            else:\n",
    "                tab_wrong_cell += 1                        \n",
    "        except:\n",
    "                tab_missing_cell += 1\n",
    "    if temp_list:\n",
    "        print(temp_list)\n",
    "    print(colored(\"\\nCorrect cells annotation: \", 'blue') +str(tab_right_cell))\n",
    "    print(colored(\"Incorrect cells annotation: \", 'blue') +str(tab_wrong_cell))\n",
    "    print(colored(\"Missing cells annotation: \", 'blue') +str(tab_missing_cell))\n",
    "else:\n",
    "    print(colored(\"Do no exist annotations for this table\", 'red'))\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d473e7-6e2c-4c78-924b-8abfe317504a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompt without Pool Output Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a66b2-34e7-4466-b1cf-c8ef3457b7cf",
   "metadata": {},
   "source": [
    "## Stats Analysys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc4e88be-ee7d-4ed6-817c-ad3e18081f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEA groundtruth path\n",
    "ann_out= \"./output_no_pool.csv\"\n",
    "\n",
    "ann_dict_no_pool = {}\n",
    "\n",
    "with open(ann_out) as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    next(spamreader)\n",
    "    for row in spamreader:\n",
    "        for element in row:\n",
    "            my_list = element.split(\",\")\n",
    "            table_id = my_list[0]\n",
    "            if(my_list[1] != \" No Wikidata Entities Found\"):\n",
    "                row_id = my_list[1].strip()\n",
    "                column_id = my_list[2].strip()\n",
    "                entity = my_list[3].strip()\n",
    "                if table_id not in ann_dict_no_pool:\n",
    "                    ann_dict_no_pool[table_id] = {}\n",
    "                    ann_dict_no_pool[table_id][f\"{row_id}_{column_id}\"] = entity\n",
    "                else:\n",
    "                    ann_dict_no_pool[table_id][f\"{row_id}_{column_id}\"] = entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da2ecd77-c8a1-485c-9382-9619d055040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mOutput Analysis Prompt without Pool\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mNumber of tables: \u001b[0m2568\n",
      "\u001b[34mTabled correctly annotated: \u001b[0m116 (4.52%)\n",
      "\n",
      "\u001b[1m\u001b[31mNumber of annotable cells: \u001b[0m46072\n",
      "\u001b[34mCells correctly annotated: \u001b[0m6343 (13.77%)\n",
      "\u001b[34mCells misannotated: \u001b[0m11472 (24.9%)\n",
      "\u001b[34mMissing cells' annotation: \u001b[0m28257 (61.33%)\n"
     ]
    }
   ],
   "source": [
    "right_cell = 0\n",
    "wrong_cell = 0\n",
    "missing_cell = 0\n",
    "missing_table = 0\n",
    "entire_table = 0 \n",
    "n_cell = 0\n",
    "\n",
    "for key, value in gt_dict.items():\n",
    "    if key in ann_dict_no_pool:\n",
    "        n_cell += len(gt_dict[key])\n",
    "        if gt_dict[key] == ann_dict_no_pool[key]:  \n",
    "            entire_table += 1\n",
    "            right_cell += len(ann_dict_no_pool[key])\n",
    "        else:\n",
    "            for gt_key, gt_value in gt_dict[key].items():\n",
    "                check = 0\n",
    "                try:\n",
    "                    num_cel_tab = len(gt_dict[key])\n",
    "                    if ann_dict_no_pool[key][gt_key] == gt_value:\n",
    "                        right_cell += 1\n",
    "                        check += 1\n",
    "                    else:\n",
    "                        wrong_cell += 1                        \n",
    "                except:\n",
    "                    missing_cell += 1\n",
    "                if len(gt_dict[key]) == len(ann_dict_no_pool[key]):\n",
    "                    if check == num_cel_tab:\n",
    "                        entire_table += 1\n",
    "\n",
    "\n",
    "print(colored(\"Output Analysis Prompt without Pool\",'red', attrs=['bold']))\n",
    "print(\"\")\n",
    "\n",
    "print(colored(\"Number of tables: \", 'red', attrs=['bold'])+ str(len(ann_dict_no_pool)))  \n",
    "print(colored(\"Tabled correctly annotated: \", 'blue')+str(entire_table) + \" (\"+str(round(entire_table/len(ann_dict)*100, 2))+\"%)\")\n",
    "print(\"\")\n",
    "print(colored(\"Number of annotable cells: \", 'red', attrs=['bold'])+ str(n_cell))\n",
    "print(colored(\"Cells correctly annotated: \", 'blue')+str(right_cell)+\" (\"+str(round(right_cell/n_cell*100, 2))+\"%)\")\n",
    "print(colored(\"Cells misannotated: \", 'blue')+str(wrong_cell)+\" (\"+str(round(wrong_cell/n_cell*100, 2))+\"%)\")       \n",
    "print(colored(\"Missing cells' annotation: \", 'blue')+str(missing_cell)+\" (\"+str(round(missing_cell/n_cell*100, 2))+\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16476031-0fc7-44f1-818c-c52a36ab48bf",
   "metadata": {},
   "source": [
    "## Table Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1e905e-94e3-4f87-bf96-a805554b75b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZK2S0Y91\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mgt_dict\u001b[49m[key]\n\u001b[1;32m      4\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m temp_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gt_dict' is not defined"
     ]
    }
   ],
   "source": [
    "key = \"ZK2S0Y91\"\n",
    "value = gt_dict[key]\n",
    "\n",
    "i = 0\n",
    "temp_list = []\n",
    "print(colored(\"\\nGROUNDTRUTH ANNOTATIONS: \" + key , 'red', attrs=['bold']))\n",
    "for col_row, value in gt_dict[key].items():\n",
    "    temp_list.append(col_row + \":\" + value)\n",
    "    if(len(temp_list) == 3):\n",
    "        print(temp_list)\n",
    "        temp_list = []\n",
    "if temp_list:\n",
    "    print(temp_list)\n",
    "print(colored(\"\\nGPT ANNOTATIONS: \", 'red', attrs=['bold']))\n",
    "if key in ann_dict_no_pool:\n",
    "    for col_row, value in ann_dict_no_pool[key].items():\n",
    "        temp_list.append(col_row + \":\" + value)\n",
    "        if(len(temp_list) == 3):\n",
    "            print(temp_list)\n",
    "            temp_list = []\n",
    "        try:\n",
    "            if gt_dict[key][col_row] == value:\n",
    "                tab_right_cell += 1\n",
    "            else:\n",
    "                tab_wrong_cell += 1                        \n",
    "        except:\n",
    "                tab_missing_cell += 1\n",
    "    if temp_list:\n",
    "        print(temp_list)\n",
    "    print(colored(\"\\nCorrect cells annotation: \", 'blue') +str(tab_right_cell))\n",
    "    print(colored(\"Incorrect cells annotation: \", 'blue') +str(tab_wrong_cell))\n",
    "    print(colored(\"Missing cells annotation: \", 'blue') +str(tab_missing_cell))\n",
    "else:\n",
    "    print(colored(\"Do no exist annotations for this table\", 'red'))\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93647b7a-f6ed-41c7-a306-d525037c4834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
